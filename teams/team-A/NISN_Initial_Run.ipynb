{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Kel - Data import and dataloader"
      ],
      "metadata": {
        "id": "pacS1SW953o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "directory = kagglehub.dataset_download(\"tarunpathak/natural-images-with-synthetic-noise\")\n",
        "\n",
        "print(\"Path to dataset files:\", directory)"
      ],
      "metadata": {
        "id": "IQppEaj66dfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8854dbe-c435-4efb-c871-037db6dbdde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'natural-images-with-synthetic-noise' dataset.\n",
            "Path to dataset files: /kaggle/input/natural-images-with-synthetic-noise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Copys kaggle dataset to content directory if it doesn't exist already.\n",
        "\n",
        "new_directory = 'nids'\n",
        "\n",
        "if not os.path.exists(new_directory):\n",
        "    shutil.copytree(directory, new_directory)\n",
        "else:\n",
        "    print(\"The directory already exists.\")"
      ],
      "metadata": {
        "id": "mtwtJ_Ks6fhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Removes all prefixes for the NISN Dataset.\n",
        "\"\"\"\n",
        "def remove_nids_prefix(dir):\n",
        "  new_fn = \"\"\n",
        "  for fn in os.listdir(dir):\n",
        "    old_fn_dir = os.path.join(dir, fn)\n",
        "    new_fn = fn.split(\"_\", 1)[1]\n",
        "    new_fn_dir = os.path.join(dir, new_fn)\n",
        "    # print(old_fn_dir, end=\" => \")\n",
        "    # print(new_fn_dir)\n",
        "    os.rename(old_fn_dir, new_fn_dir)\n",
        "\n",
        "remove_nids_prefix(\"nids/test/test/noisy images\")\n",
        "remove_nids_prefix(\"nids/train/train/noisy images\")\n",
        "remove_nids_prefix(\"nids/validate/validate/noisy images\")"
      ],
      "metadata": {
        "id": "tVkQ4pal6s_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  article dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as Datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm as tqdm_regular\n",
        "import seaborn as sns\n",
        "from torchvision.utils import make_grid\n",
        "import random\n",
        "import os\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "kHod-rvE6xEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  configuring device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  print('Running on the GPU')\n",
        "elif torch.backends.mps.is_available():\n",
        "  device = torch.device('mps')\n",
        "  print('Running on Metal')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Running on the CPU')"
      ],
      "metadata": {
        "id": "_a6hDQm29xFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9222977e-ef94-4676-96b9-e62de35a24e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creates Dataset class for Natural Image Data Set.\n",
        "\"\"\"\n",
        "class NaturalImageDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, dir, transform=None):\n",
        "        self.noisy_dir = os.path.join(dir, \"noisy images\")\n",
        "        self.clean_dir = os.path.join(dir, \"ground truth\")\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images = os.listdir(self.noisy_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        imagefn = self.images[index]\n",
        "\n",
        "        #Make sure file exists. Otherwise, return an error.\n",
        "        try:\n",
        "            noisy_image = Image.open(os.path.join(self.noisy_dir, imagefn)).convert(\"L\") #Converts to grayscale.\n",
        "            clean_image = Image.open(os.path.join(self.clean_dir, imagefn)).convert(\"L\")\n",
        "        except FileNotFoundError:\n",
        "            print (f'File Not Found: Unable to load image for the following file: {imagefn}')\n",
        "\n",
        "            return None, None\n",
        "\n",
        "        if self.transform: #Apply transforms here.\n",
        "            noisy_image = self.transform(noisy_image)\n",
        "            clean_image = self.transform(clean_image)\n",
        "\n",
        "        return noisy_image, clean_image"
      ],
      "metadata": {
        "id": "ZScHSyBa90KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(32), # TODO: Placeholder to fit in the dataset. Will remove/change this.\n",
        "    # Any other possible transformations to do here?\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "    # Interesting note: You can add other data transforms like flipLR, FlipUpDown, Stretches, Shears, crops, etc\n",
        "    # For data augmentation\n",
        "])\n",
        "\n",
        "\n",
        "training_data = NaturalImageDataSet(\"./nids/train/train\", transform=transform)\n",
        "training_NIDS_loader = DataLoader(training_data, batch_size=4, shuffle=True, num_workers=4)\n",
        "#May or may not need to be included, since the base CAE already has dataloaders.\n",
        "\n",
        "test_data = NaturalImageDataSet(\"./nids/test/test\", transform=transform)\n",
        "test_NIDS_loader = DataLoader(test_data, batch_size=4, shuffle=False, num_workers=4)\n",
        "\n",
        "validation_data = NaturalImageDataSet(\"./nids/validate/validate\", transform=transform)\n",
        "validate_NIDS_loader = DataLoader(validation_data, batch_size=4, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "VFn40RQ292hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars(training_NIDS_loader.dataset)"
      ],
      "metadata": {
        "id": "R8x0W0IeqQjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for noisy, clean in training_NIDS_loader:\n",
        "  print(noisy.shape)\n",
        "  print(clean.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "391oltGBnmFs",
        "outputId": "15ccd9e2-45f7-4a92-f650-848ebe304f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Not Found: Unable to load image for the following file: a3f82df79a_c.jpg\n",
            "File Not Found: Unable to load image for the following file: c2698a66f6_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 1897c3626a_c.jpgFile Not Found: Unable to load image for the following file: a04a48f292_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 9a798e886f_c.jpgFile Not Found: Unable to load image for the following file: 069c9e44d0_c.jpg\n",
            "File Not Found: Unable to load image for the following file: d31cba482f_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 6c0257c33c_c.jpg\n",
            "File Not Found: Unable to load image for the following file: cfba64d494_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 30efa2ec00_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 81c285a14f_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 336bc92c75_c.jpgFile Not Found: Unable to load image for the following file: e7c42ec1bb_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 9974ddfef7_c.jpgFile Not Found: Unable to load image for the following file: b31702794c_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 5cc3edb5a3_c.jpgFile Not Found: Unable to load image for the following file: 1537cffb0f_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 1c51324369_c.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-239090746.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_NIDS_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Not Found: Unable to load image for the following file: 5f4eb31448_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 5d9baa0c3c_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 1ffe2d6c62_c.jpgFile Not Found: Unable to load image for the following file: 975e35935f_c.jpg"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mine - Architecture initialization"
      ],
      "metadata": {
        "id": "3D35HdGE589I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  defining encoder\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=16, latent_dim=1000, act_fn=nn.ReLU()):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1), # (32, 32)\n",
        "        act_fn,\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.Conv2d(out_channels, 2*out_channels, 3, padding=1, stride=2), # (16, 16)\n",
        "        act_fn,\n",
        "        nn.Conv2d(2*out_channels, 2*out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.Conv2d(2*out_channels, 4*out_channels, 3, padding=1, stride=2), # (8, 8)\n",
        "        act_fn,\n",
        "        nn.Conv2d(4*out_channels, 4*out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(4*out_channels*8*8, latent_dim),\n",
        "        act_fn\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, self.in_channels, 32, 32)\n",
        "    output = self.net(x)\n",
        "    return output\n",
        "\n",
        "\n",
        "#  defining decoder\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=16, latent_dim=1000, act_fn=nn.ReLU()):\n",
        "    super().__init__()\n",
        "\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "    self.linear = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 4*out_channels*8*8),\n",
        "        act_fn\n",
        "    )\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(4*out_channels, 4*out_channels, 3, padding=1), # (8, 8)\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(4*out_channels, 2*out_channels, 3, padding=1,\n",
        "                           stride=2, output_padding=1), # (16, 16)\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(2*out_channels, 2*out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(2*out_channels, out_channels, 3, padding=1,\n",
        "                           stride=2, output_padding=1), # (32, 32)\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(out_channels, out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(out_channels, in_channels, 3, padding=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.linear(x)\n",
        "    output = output.view(-1, 4*self.out_channels, 8, 8)\n",
        "    output = self.conv(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "#  defining autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.encoder.to(device)\n",
        "\n",
        "    self.decoder = decoder\n",
        "    self.decoder.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "metadata": {
        "id": "c14UaQwr6JqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yousef - Hyperparams and training loop"
      ],
      "metadata": {
        "id": "SI4uN9Iq6AgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional, Tuple, Dict, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, SequentialLR, LinearLR"
      ],
      "metadata": {
        "id": "B4OewH3s66vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVxVHlfJnTmJ"
      },
      "source": [
        "Util:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_all(seed: int = 42):\n",
        "    import random\n",
        "    import numpy as np\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def psnr_from_mse(mse: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"PSNR in dB assuming targets in [0,1]\"\"\"\n",
        "    return 10.0 * torch.log10(1.0 / (mse + 1e-12))\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Tracks running average of a scalar.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.sum = 0.0\n",
        "        self.count = 0\n",
        "    def update(self, val: float, n: int = 1):\n",
        "        self.sum += float(val) * n\n",
        "        self.count += n\n",
        "    @property\n",
        "    def avg(self) -> float:\n",
        "        return self.sum / max(1, self.count)"
      ],
      "metadata": {
        "id": "HUMn5SG87f41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparamtere:"
      ],
      "metadata": {
        "id": "PF2YKGYH8lXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51EV4Mi3nnZS"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TrainConfig:\n",
        "    # Core\n",
        "    epochs: int = 20\n",
        "    batch_size: int = 128  # TODO: reduce once we modify architecture\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 0.0\n",
        "    optimizer: str = \"adamw\"  # one of {\"adam\", \"adamw\", \"sgd\"}\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler: str = \"cosine\"  # or \"none\"\n",
        "    warmup_epochs: int = 0\n",
        "\n",
        "    # Optimization niceties\n",
        "    amp: bool = True  # automatic mixed precision\n",
        "    grad_clip_norm: float = 1.0  # 0 or None to disable\n",
        "    accum_steps: int = 1  # gradient accumulation steps\n",
        "\n",
        "    # Repro / IO\n",
        "    seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    out_dir: str = \"./outputs\"\n",
        "    ckpt_last: str = \"last.pt\"\n",
        "    ckpt_best: str = \"best.pt\"\n",
        "    resume: Optional[bool] = False\n",
        "\n",
        "    # Loss\n",
        "    loss: str = \"mse\"  # {\"mse\", \"l1\", \"charbonnier\"}\n",
        "    charbonnier_eps: float = 1e-3\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Factory Function:"
      ],
      "metadata": {
        "id": "h1UM1Kjo8hcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_optimizer(model: nn.Module, cfg: TrainConfig) -> Optimizer:\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    if cfg.optimizer.lower() == \"adam\":\n",
        "        return torch.optim.Adam(params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    if cfg.optimizer.lower() == \"adamw\":\n",
        "        return torch.optim.AdamW(params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    if cfg.optimizer.lower() == \"sgd\":\n",
        "        return torch.optim.SGD(params, lr=cfg.lr, weight_decay=cfg.weight_decay, momentum=0.9, nesterov=True)\n",
        "    raise ValueError(\"Unsupported optimizer: %s\" % cfg.optimizer)\n",
        "\n",
        "\n",
        "def create_scheduler(opt: Optimizer, cfg: TrainConfig, steps_per_epoch: int) -> Optional[_LRScheduler]:\n",
        "    if cfg.scheduler == \"none\":\n",
        "        return None\n",
        "    if cfg.scheduler == \"cosine\":\n",
        "        total_epochs = cfg.epochs\n",
        "        if cfg.warmup_epochs > 0:\n",
        "            warmup = LinearLR(opt, start_factor=0.01, end_factor=1.0, total_iters=cfg.warmup_epochs * steps_per_epoch)\n",
        "            cosine = CosineAnnealingLR(opt, T_max=max(1, (total_epochs - cfg.warmup_epochs) * steps_per_epoch))\n",
        "            return SequentialLR(opt, schedulers=[warmup, cosine], milestones=[cfg.warmup_epochs * steps_per_epoch])\n",
        "        else:\n",
        "            return CosineAnnealingLR(opt, T_max=max(1, total_epochs * steps_per_epoch))\n",
        "    raise ValueError(\"Unsupported scheduler: %s\" % cfg.scheduler)\n",
        "\n",
        "\n",
        "def create_loss(cfg: TrainConfig):\n",
        "    if cfg.loss == \"mse\":\n",
        "        return nn.MSELoss(reduction='mean')\n",
        "    if cfg.loss == \"l1\":\n",
        "        return nn.L1Loss(reduction='mean')\n",
        "    if cfg.loss == \"charbonnier\":\n",
        "        class Charbonnier(nn.Module):\n",
        "            def __init__(self, eps: float = 1e-3):\n",
        "                super().__init__()\n",
        "                self.eps = eps\n",
        "            def forward(self, pred, target):\n",
        "                diff = pred - target\n",
        "                return torch.mean(torch.sqrt(diff * diff + self.eps * self.eps))\n",
        "        return Charbonnier(cfg.charbonnier_eps)\n",
        "    raise ValueError(\"Unsupported loss: %s\" % cfg.loss)"
      ],
      "metadata": {
        "id": "GuZAwyLE7qbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For every epoch:\n",
        "    train\n",
        "    validate\n",
        "\n",
        "test"
      ],
      "metadata": {
        "id": "yKLjVZVaHutb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Loop:"
      ],
      "metadata": {
        "id": "O_Kwy6Hy8cum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "        model: nn.Module,\n",
        "        train_loader: DataLoader,\n",
        "        # val_loader: DataLoader,\n",
        "        optimizer: Optimizer,\n",
        "        device: str,\n",
        "        loss_fn: nn.Module,\n",
        "        scaler: Optional[torch.cuda.amp.GradScaler],\n",
        "        cfg: TrainConfig\n",
        ") -> Dict[str, float]:\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Training logs\n",
        "    train_loss_meter = AverageMeter()\n",
        "    train_psnr_meter = AverageMeter()\n",
        "\n",
        "    # # Val logs\n",
        "    # val_loss_meter = AverageMeter()\n",
        "    # val_psnr_meter = AverageMeter()\n",
        "\n",
        "    for step, (noisy, clean) in enumerate(train_loader, start=1):\n",
        "        noisy = noisy.to(device, non_blocking=True)\n",
        "        clean = clean.to(device, non_blocking=True)\n",
        "\n",
        "        # with torch.cuda.amp.autocast(enabled=cfg.amp):\n",
        "        #     recon = model(noisy)\n",
        "        #     loss = loss_fn(recon, clean) / max(1, cfg.accum_steps)\n",
        "\n",
        "        # if scaler is not None and cfg.amp:\n",
        "        #     scaler.scale(loss).backward()\n",
        "        # else:\n",
        "        #     loss.backward()\n",
        "\n",
        "        # if step % cfg.accum_steps == 0:\n",
        "        #     if cfg.grad_clip_norm and cfg.grad_clip_norm > 0:\n",
        "        #         if scaler is not None and cfg.amp:\n",
        "        #             scaler.unscale_(optimizer)\n",
        "        #         torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip_norm)\n",
        "\n",
        "        #     if scaler is not None and cfg.amp:\n",
        "        #         scaler.step(optimizer)\n",
        "        #         scaler.update()\n",
        "        #     else:\n",
        "        #         optimizer.step()\n",
        "        #     optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass\n",
        "        recon = model(noisy)\n",
        "\n",
        "        # Loss calculation\n",
        "        loss = loss_fn(recon, clean)\n",
        "\n",
        "        # Gradient calculation\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Metrics\n",
        "        with torch.no_grad():\n",
        "            batch_mse = F.mse_loss(recon, clean, reduction='none').view(clean.size(0), -1).mean(dim=1)\n",
        "            batch_psnr = psnr_from_mse(batch_mse).mean().item()\n",
        "            train_loss_meter.update(loss.item() * max(1, cfg.accum_steps), n=clean.size(0))\n",
        "            train_psnr_meter.update(batch_psnr, n=clean.size(0))\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #     for step, (noisy, clean) in enumerate(val_loader, start=1):\n",
        "    #         noisy = noisy.to(device, non_blocking=True)\n",
        "    #         clean = clean.to(device, non_blocking=True)\n",
        "\n",
        "    #         recon = model(noisy)\n",
        "\n",
        "    #         batch_mse = F.mse_loss(recon, clean, reduction='none').view(clean.size(0), -1).mean(dim=1)\n",
        "    #         batch_psnr = psnr_from_mse(batch_mse).mean().item()\n",
        "    #         val_loss_meter.update(loss.item() * max(1, cfg.accum_steps), n=clean.size(0))\n",
        "    #         val_psnr_meter.update(batch_psnr, n=clean.size(0))\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"loss\": train_loss_meter.avg,\n",
        "        \"psnr\": train_psnr_meter.avg,\n",
        "        # \"val_loss\": val_loss_meter.avg,\n",
        "        # \"val_psnr\": val_psnr_meter.avg\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             test_loader: DataLoader,\n",
        "             device: str,\n",
        "             loss_fn: nn.Module) -> Dict[str, float]:\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter()\n",
        "    psnr_meter = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        for noisy, clean in test_loader:\n",
        "            noisy = noisy.to(device, non_blocking=True)\n",
        "            clean = clean.to(device, non_blocking=True)\n",
        "            recon = model(noisy)\n",
        "            loss = loss_fn(recon, clean)\n",
        "            batch_mse = F.mse_loss(recon, clean, reduction='none').view(clean.size(0), -1).mean(dim=1)\n",
        "            batch_psnr = psnr_from_mse(batch_mse).mean().item()\n",
        "            loss_meter.update(loss.item(), n=clean.size(0))\n",
        "            psnr_meter.update(batch_psnr, n=clean.size(0))\n",
        "    return {\"loss\": loss_meter.avg, \"psnr\": psnr_meter.avg}"
      ],
      "metadata": {
        "id": "Np5u2JhL7znI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks:"
      ],
      "metadata": {
        "id": "QOU1Wi2I8XxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(\n",
        "    path: str,\n",
        "    model: nn.Module,\n",
        "    scheduler: Optional[_LRScheduler],\n",
        "    scaler: Optional[torch.cuda.amp.GradScaler],\n",
        "    epoch: int,\n",
        "    cfg: TrainConfig,\n",
        "    best_val: float\n",
        "):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\n",
        "        \"model\": model.state_dict(),\n",
        "        \"scheduler\": None if scheduler is None else scheduler.state_dict(),\n",
        "        \"scaler\": None if scaler is None else scaler.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"cfg\": asdict(cfg),\n",
        "        \"best_val\": best_val,\n",
        "    }, path)\n",
        "\n",
        "\n",
        "def load_checkpoint(\n",
        "    path: str,\n",
        "    model: nn.Module,\n",
        "    scheduler: Optional[_LRScheduler] = None,\n",
        "    scaler: Optional[torch.cuda.amp.GradScaler] = None,\n",
        "    map_location: Optional[str] = None\n",
        ") -> Tuple[int, float, TrainConfig]:\n",
        "    ckpt = torch.load(path, map_location=map_location)\n",
        "    model.load_state_dict(ckpt[\"model\"])\n",
        "    # if optimizer is not None and ckpt.get(\"optimizer\") is not None:\n",
        "    #     optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "    if scheduler is not None and ckpt.get(\"scheduler\") is not None:\n",
        "        scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "    if scaler is not None and ckpt.get(\"scaler\") is not None:\n",
        "        scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "    start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "    best_val = float(ckpt.get(\"best_val\", float(\"inf\")))\n",
        "    cfg_dict = ckpt.get(\"cfg\", {})\n",
        "    cfg = TrainConfig(**cfg_dict) if cfg_dict else TrainConfig()\n",
        "    return start_epoch, best_val, cfg"
      ],
      "metadata": {
        "id": "mUIrw-Cw73Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit Loop:"
      ],
      "metadata": {
        "id": "6eJenHcW8Tso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model: nn.Module,\n",
        "        train_loader: DataLoader,\n",
        "        val_loader: DataLoader,\n",
        "        cfg: TrainConfig) -> Dict[str, Any]:\n",
        "    seed_all(cfg.seed)\n",
        "    device = cfg.device\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = create_optimizer(model, cfg)\n",
        "    steps_per_epoch = max(1, math.ceil(len(train_loader.dataset) / (cfg.batch_size)))\n",
        "    scheduler = create_scheduler(optimizer, cfg, steps_per_epoch)\n",
        "    loss_fn = create_loss(cfg)\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp)\n",
        "\n",
        "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "    last_path = os.path.join(cfg.out_dir, cfg.ckpt_last)\n",
        "    best_path = os.path.join(cfg.out_dir, cfg.ckpt_best)\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    if cfg.resume and os.path.isfile(cfg.resume):\n",
        "        start_epoch, best_val_loss, _ = load_checkpoint(cfg.resume, model, optimizer, scheduler, scaler, map_location=device)\n",
        "        print(f\"[Resume] Starting from epoch {start_epoch}, best_val_loss={best_val_loss:.6f}\")\n",
        "\n",
        "    log_dict = {}\n",
        "\n",
        "    for epoch in range(start_epoch, cfg.epochs + 1):\n",
        "        # Train\n",
        "        train_stats = train_one_epoch(model, train_loader, optimizer, device, loss_fn, scaler, cfg)\n",
        "        if scheduler is not None:\n",
        "            # Step per-iteration schedulers are already stepped inside; ours is per-iteration via SequentialLR/LinearLR\n",
        "            # For simplicity, step here once per epoch when using epoch-based T_max.\n",
        "            try:\n",
        "                scheduler.step()\n",
        "            except TypeError:\n",
        "                # Some schedulers require step() every iteration; we chose epoch-wise to keep it simple.\n",
        "                pass\n",
        "\n",
        "        # Validate\n",
        "        val_stats = evaluate(model, val_loader, device, loss_fn)\n",
        "\n",
        "        # Logging\n",
        "        print(f\"Epoch {epoch:03d}/{cfg.epochs} | \"\n",
        "              f\"Train loss {train_stats['loss']:.6f} PSNR {train_stats['psnr']:.2f} dB | \"\n",
        "              f\"Val loss {val_stats['loss']:.6f} PSNR {val_stats['psnr']:.2f} dB | \"\n",
        "              f\"LR {optimizer.param_groups[0]['lr']:.6g}\")\n",
        "        log_dict[epoch] = {**train_stats, **val_stats}\n",
        "\n",
        "        # Checkpoints\n",
        "        save_checkpoint(last_path, model, optimizer, scheduler, scaler, epoch, cfg, best_val_loss)\n",
        "        if val_stats[\"loss\"] < best_val_loss:\n",
        "            best_val_loss = val_stats[\"loss\"]\n",
        "            save_checkpoint(best_path, model, optimizer, scheduler, scaler, epoch, cfg, best_val_loss)\n",
        "            print(f\"[Best] Val loss improved to {best_val_loss:.6f} -> saved {best_path}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return {\"best_val_loss\": best_val_loss}, log_dict\n"
      ],
      "metadata": {
        "id": "oRk0AbBW78Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Driver Code"
      ],
      "metadata": {
        "id": "TXyAfwf6ji4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Autoencoder(Encoder(in_channels=3), Decoder(in_channels=3))\n",
        "cfg = TrainConfig(\n",
        "    epochs=5,\n",
        "    batch_size=4,\n",
        "    optimizer=\"Adam\",\n",
        "    device=\"cpu\",\n",
        "    out_dir=\"./outputs\",\n",
        ")"
      ],
      "metadata": {
        "id": "o1pOXEroiuQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss, log_dict = fit(model, training_NIDS_loader, validate_NIDS_loader, cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q6rttFlhlFLH",
        "outputId": "bd2cb3ca-20f7-49b9-ab73-db0e2fee29dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3298606942.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Not Found: Unable to load image for the following file: f0aca7f1f0_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 549a32c9aa_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 20a90fa1e8_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 0a0e7c7871_c.jpgFile Not Found: Unable to load image for the following file: d525d0bc2f_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: acd32b2f20_c.jpgFile Not Found: Unable to load image for the following file: 9365075b11_c.jpgFile Not Found: Unable to load image for the following file: de1a839d9f_c.jpg\n",
            "\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 0f7e3f7423_c.jpgFile Not Found: Unable to load image for the following file: 4585aee857_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: bb0af36076_c.jpgFile Not Found: Unable to load image for the following file: 6c99074aa7_c.jpgFile Not Found: Unable to load image for the following file: 845d5976c0_c.jpg\n",
            "\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 6fee1f0be2_c.jpgFile Not Found: Unable to load image for the following file: 6afc92e0f7_c.jpg\n",
            "File Not Found: Unable to load image for the following file: b1336e35a4_c.jpg\n",
            "File Not Found: Unable to load image for the following file: f714b69315_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: 1069d2c23c_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 5402375c77_c.jpgFile Not Found: Unable to load image for the following file: 24275978b1_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: c4165cfef6_c.jpg\n",
            "File Not Found: Unable to load image for the following file: b400db7c92_c.jpg\n",
            "File Not Found: Unable to load image for the following file: c7fd0cba1f_c.jpgFile Not Found: Unable to load image for the following file: cb7025542b_c.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2055575396.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_NIDS_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_NIDS_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3298606942.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, cfg)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Step per-iteration schedulers are already stepped inside; ours is per-iteration via SequentialLR/LinearLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3989461252.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, optimizer, device, loss_fn, scaler, cfg)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# val_psnr_meter = AverageMeter()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnoisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mnoisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File Not Found: Unable to load image for the following file: d94bedc68d_c.jpg\n",
            "File Not Found: Unable to load image for the following file: 0929cbb656_c.jpgFile Not Found: Unable to load image for the following file: 5109d9f4a6_c.jpg\n",
            "\n",
            "File Not Found: Unable to load image for the following file: be958f9312_c.jpgFile Not Found: Unable to load image for the following file: 8ce5c7621a_c.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Krishna - Metrics log and test code"
      ],
      "metadata": {
        "id": "hjS_mgZG6DIc"
      }
    }
  ]
}