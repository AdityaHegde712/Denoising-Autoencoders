{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pacS1SW953o3"
      },
      "source": [
        "Kel - Data import and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQppEaj66dfQ",
        "outputId": "d8854dbe-c435-4efb-c871-037db6dbdde3"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "directory = kagglehub.dataset_download(\"tarunpathak/natural-images-with-synthetic-noise\")\n",
        "\n",
        "print(\"Path to dataset files:\", directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtwtJ_Ks6fhM"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Copys kaggle dataset to content directory if it doesn't exist already.\n",
        "\n",
        "new_directory = 'nids'\n",
        "\n",
        "if not os.path.exists(new_directory):\n",
        "    shutil.copytree(directory, new_directory)\n",
        "else:\n",
        "    print(\"The directory already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVkQ4pal6s_M"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Helper function for prefix removal\n",
        "\"\"\"\n",
        "def remove_noise_prefix(fn):\n",
        "    prefixes = [\"gauss_\", \"poisson_\", \"salt and pepper_\", \"speckle_\"]\n",
        "\n",
        "    for prefix in prefixes:\n",
        "      if fn.startswith(prefix):\n",
        "        return fn.split(\"_\", 1)[1]\n",
        "\n",
        "    return fn\n",
        "\n",
        "\"\"\"\n",
        "  Removes all prefixes for the NISN Dataset.\n",
        "\"\"\"\n",
        "def remove_nids_prefix(dir):\n",
        "  new_fn = \"\"\n",
        "  for fn in os.listdir(dir):\n",
        "    old_fn_dir = os.path.join(dir, fn)\n",
        "    new_fn = remove_noise_prefix(fn)\n",
        "    new_fn_dir = os.path.join(dir, new_fn)\n",
        "\n",
        "    if old_fn_dir != new_fn_dir:\n",
        "          os.rename(old_fn_dir, new_fn_dir)\n",
        "    else:\n",
        "          print(f'Skipping file: {old_fn_dir} as it either the prefix has already been removed or it does not have a prefix.')\n",
        "\n",
        "remove_nids_prefix(\"nids/test/test/noisy images\")\n",
        "remove_nids_prefix(\"nids/train/train/noisy images\")\n",
        "remove_nids_prefix(\"nids/validate/validate/noisy images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHod-rvE6xEZ"
      },
      "outputs": [],
      "source": [
        "#  article dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as Datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm as tqdm_regular\n",
        "import seaborn as sns\n",
        "from torchvision.utils import make_grid\n",
        "import random\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a6hDQm29xFM",
        "outputId": "9222977e-ef94-4676-96b9-e62de35a24e0"
      },
      "outputs": [],
      "source": [
        "#  configuring device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  print('Running on the GPU')\n",
        "elif torch.backends.mps.is_available():\n",
        "  device = torch.device('mps')\n",
        "  print('Running on Metal')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Running on the CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZScHSyBa90KE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Creates Dataset class for Natural Image Data Set.\n",
        "\"\"\"\n",
        "class NaturalImageDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, dir, transform=None):\n",
        "        self.noisy_dir = os.path.join(dir, \"noisy images\")\n",
        "        self.clean_dir = os.path.join(dir, \"ground truth\")\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images = os.listdir(self.noisy_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        imagefn = self.images[index]\n",
        "        noisy_image_fp = os.path.join(self.noisy_dir, imagefn)\n",
        "        clean_image_fp = os.path.join(self.clean_dir, imagefn)\n",
        "\n",
        "        #Make sure file exists. Otherwise, return an error.\n",
        "        try:\n",
        "            noisy_image = Image.open(noisy_image_fp).convert(\"RGB\") #Converts to grayscale.\n",
        "            clean_image = Image.open(clean_image_fp).convert(\"RGB\")\n",
        "        except FileNotFoundError:\n",
        "            print (f'File Not Found: Unable to load matching ground truth image for the following image: {noisy_image_fp}')\n",
        "            print (f'Missing ground truth image: {clean_image_fp}')\n",
        "            return None, None\n",
        "\n",
        "        if self.transform: #Apply transforms here.\n",
        "            noisy_image = self.transform(noisy_image)\n",
        "            clean_image = self.transform(clean_image)\n",
        "\n",
        "        return noisy_image, clean_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFn40RQ292hH"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(32), # TODO: Placeholder to fit in the dataset. Will remove/change this.\n",
        "    # Any other possible transformations to do here?\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "    # Interesting note: You can add other data transforms like flipLR, FlipUpDown, Stretches, Shears, crops, etc\n",
        "    # For data augmentation\n",
        "])\n",
        "\n",
        "\n",
        "training_data = NaturalImageDataSet(\"./nids/train/train\", transform=transform)\n",
        "training_NIDS_loader = DataLoader(training_data, batch_size=4, shuffle=True, num_workers=4)\n",
        "#May or may not need to be included, since the base CAE already has dataloaders.\n",
        "\n",
        "test_data = NaturalImageDataSet(\"./nids/test/test\", transform=transform)\n",
        "test_NIDS_loader = DataLoader(test_data, batch_size=4, shuffle=False, num_workers=4)\n",
        "\n",
        "validation_data = NaturalImageDataSet(\"./nids/validate/validate\", transform=transform)\n",
        "validate_NIDS_loader = DataLoader(validation_data, batch_size=4, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8x0W0IeqQjZ"
      },
      "outputs": [],
      "source": [
        "vars(training_NIDS_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "391oltGBnmFs",
        "outputId": "15ccd9e2-45f7-4a92-f650-848ebe304f32"
      },
      "outputs": [],
      "source": [
        "for noisy, clean in training_NIDS_loader:\n",
        "  print(noisy.shape)\n",
        "  print(clean.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D35HdGE589I"
      },
      "source": [
        "Mine - Architecture initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c14UaQwr6JqI"
      },
      "outputs": [],
      "source": [
        "#  defining encoder\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=16, latent_dim=1000, act_fn=nn.ReLU()):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1), # (32, 32)\n",
        "        act_fn,\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.Conv2d(out_channels, 2*out_channels, 3, padding=1, stride=2), # (16, 16)\n",
        "        act_fn,\n",
        "        nn.Conv2d(2*out_channels, 2*out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.Conv2d(2*out_channels, 4*out_channels, 3, padding=1, stride=2), # (8, 8)\n",
        "        act_fn,\n",
        "        nn.Conv2d(4*out_channels, 4*out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(4*out_channels*8*8, latent_dim),\n",
        "        act_fn\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, self.in_channels, 32, 32)\n",
        "    output = self.net(x)\n",
        "    return output\n",
        "\n",
        "\n",
        "#  defining decoder\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=16, latent_dim=1000, act_fn=nn.ReLU()):\n",
        "    super().__init__()\n",
        "\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "    self.linear = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 4*out_channels*8*8),\n",
        "        act_fn\n",
        "    )\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(4*out_channels, 4*out_channels, 3, padding=1), # (8, 8)\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(4*out_channels, 2*out_channels, 3, padding=1,\n",
        "                           stride=2, output_padding=1), # (16, 16)\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(2*out_channels, 2*out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(2*out_channels, out_channels, 3, padding=1,\n",
        "                           stride=2, output_padding=1), # (32, 32)\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(out_channels, out_channels, 3, padding=1),\n",
        "        act_fn,\n",
        "        nn.ConvTranspose2d(out_channels, in_channels, 3, padding=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.linear(x)\n",
        "    output = output.view(-1, 4*self.out_channels, 8, 8)\n",
        "    output = self.conv(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "#  defining autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.encoder.to(device)\n",
        "\n",
        "    self.decoder = decoder\n",
        "    self.decoder.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI4uN9Iq6AgD"
      },
      "source": [
        "Yousef - Hyperparams and training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4OewH3s66vk"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional, Tuple, Dict, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, SequentialLR, LinearLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVxVHlfJnTmJ"
      },
      "source": [
        "Util:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUMn5SG87f41"
      },
      "outputs": [],
      "source": [
        "def seed_all(seed: int = 42):\n",
        "    import random\n",
        "    import numpy as np\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def psnr_from_mse(mse: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"PSNR in dB assuming targets in [0,1]\"\"\"\n",
        "    return 10.0 * torch.log10(1.0 / (mse + 1e-12))\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Tracks running average of a scalar.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.sum = 0.0\n",
        "        self.count = 0\n",
        "    def update(self, val: float, n: int = 1):\n",
        "        self.sum += float(val) * n\n",
        "        self.count += n\n",
        "    @property\n",
        "    def avg(self) -> float:\n",
        "        return self.sum / max(1, self.count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF2YKGYH8lXl"
      },
      "source": [
        "Hyperparamtere:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51EV4Mi3nnZS"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TrainConfig:\n",
        "    # Core\n",
        "    epochs: int = 20\n",
        "    batch_size: int = 128  # TODO: reduce once we modify architecture\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 0.0\n",
        "    optimizer: str = \"adamw\"  # one of {\"adam\", \"adamw\", \"sgd\"}\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler: str = \"cosine\"  # or \"none\"\n",
        "    warmup_epochs: int = 0\n",
        "\n",
        "    # Optimization niceties\n",
        "    amp: bool = True  # automatic mixed precision\n",
        "    grad_clip_norm: float = 1.0  # 0 or None to disable\n",
        "    accum_steps: int = 1  # gradient accumulation steps\n",
        "\n",
        "    # Repro / IO\n",
        "    seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    out_dir: str = \"./outputs\"\n",
        "    ckpt_last: str = \"last.pt\"\n",
        "    ckpt_best: str = \"best.pt\"\n",
        "    resume: Optional[bool] = False\n",
        "\n",
        "    # Loss\n",
        "    loss: str = \"mse\"  # {\"mse\", \"l1\", \"charbonnier\"}\n",
        "    charbonnier_eps: float = 1e-3\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1UM1Kjo8hcE"
      },
      "source": [
        "Factory Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuZAwyLE7qbp"
      },
      "outputs": [],
      "source": [
        "def create_optimizer(model: nn.Module, cfg: TrainConfig) -> Optimizer:\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    if cfg.optimizer.lower() == \"adam\":\n",
        "        return torch.optim.Adam(params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    if cfg.optimizer.lower() == \"adamw\":\n",
        "        return torch.optim.AdamW(params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    if cfg.optimizer.lower() == \"sgd\":\n",
        "        return torch.optim.SGD(params, lr=cfg.lr, weight_decay=cfg.weight_decay, momentum=0.9, nesterov=True)\n",
        "    raise ValueError(\"Unsupported optimizer: %s\" % cfg.optimizer)\n",
        "\n",
        "\n",
        "def create_scheduler(opt: Optimizer, cfg: TrainConfig, steps_per_epoch: int) -> Optional[_LRScheduler]:\n",
        "    if cfg.scheduler == \"none\":\n",
        "        return None\n",
        "    if cfg.scheduler == \"cosine\":\n",
        "        total_epochs = cfg.epochs\n",
        "        if cfg.warmup_epochs > 0:\n",
        "            warmup = LinearLR(opt, start_factor=0.01, end_factor=1.0, total_iters=cfg.warmup_epochs * steps_per_epoch)\n",
        "            cosine = CosineAnnealingLR(opt, T_max=max(1, (total_epochs - cfg.warmup_epochs) * steps_per_epoch))\n",
        "            return SequentialLR(opt, schedulers=[warmup, cosine], milestones=[cfg.warmup_epochs * steps_per_epoch])\n",
        "        else:\n",
        "            return CosineAnnealingLR(opt, T_max=max(1, total_epochs * steps_per_epoch))\n",
        "    raise ValueError(\"Unsupported scheduler: %s\" % cfg.scheduler)\n",
        "\n",
        "\n",
        "def create_loss(cfg: TrainConfig):\n",
        "    if cfg.loss == \"mse\":\n",
        "        return nn.MSELoss(reduction='mean')\n",
        "    if cfg.loss == \"l1\":\n",
        "        return nn.L1Loss(reduction='mean')\n",
        "    if cfg.loss == \"charbonnier\":\n",
        "        class Charbonnier(nn.Module):\n",
        "            def __init__(self, eps: float = 1e-3):\n",
        "                super().__init__()\n",
        "                self.eps = eps\n",
        "            def forward(self, pred, target):\n",
        "                diff = pred - target\n",
        "                return torch.mean(torch.sqrt(diff * diff + self.eps * self.eps))\n",
        "        return Charbonnier(cfg.charbonnier_eps)\n",
        "    raise ValueError(\"Unsupported loss: %s\" % cfg.loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKLjVZVaHutb"
      },
      "source": [
        "For every epoch:\n",
        "    train\n",
        "    validate\n",
        "\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Kwy6Hy8cum"
      },
      "source": [
        "Train Loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np5u2JhL7znI"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(\n",
        "        model: nn.Module,\n",
        "        train_loader: DataLoader,\n",
        "        # val_loader: DataLoader,\n",
        "        optimizer: Optimizer,\n",
        "        device: str,\n",
        "        loss_fn: nn.Module,\n",
        "        scaler: Optional[torch.cuda.amp.GradScaler],\n",
        "        cfg: TrainConfig\n",
        ") -> Dict[str, float]:\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Training logs\n",
        "    train_loss_meter = AverageMeter()\n",
        "    train_psnr_meter = AverageMeter()\n",
        "\n",
        "    # # Val logs\n",
        "    # val_loss_meter = AverageMeter()\n",
        "    # val_psnr_meter = AverageMeter()\n",
        "\n",
        "    for step, (noisy, clean) in enumerate(train_loader, start=1):\n",
        "        noisy = noisy.to(device, non_blocking=True)\n",
        "        clean = clean.to(device, non_blocking=True)\n",
        "\n",
        "        # with torch.cuda.amp.autocast(enabled=cfg.amp):\n",
        "        #     recon = model(noisy)\n",
        "        #     loss = loss_fn(recon, clean) / max(1, cfg.accum_steps)\n",
        "\n",
        "        # if scaler is not None and cfg.amp:\n",
        "        #     scaler.scale(loss).backward()\n",
        "        # else:\n",
        "        #     loss.backward()\n",
        "\n",
        "        # if step % cfg.accum_steps == 0:\n",
        "        #     if cfg.grad_clip_norm and cfg.grad_clip_norm > 0:\n",
        "        #         if scaler is not None and cfg.amp:\n",
        "        #             scaler.unscale_(optimizer)\n",
        "        #         torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip_norm)\n",
        "\n",
        "        #     if scaler is not None and cfg.amp:\n",
        "        #         scaler.step(optimizer)\n",
        "        #         scaler.update()\n",
        "        #     else:\n",
        "        #         optimizer.step()\n",
        "        #     optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass\n",
        "        recon = model(noisy)\n",
        "\n",
        "        # Loss calculation\n",
        "        loss = loss_fn(recon, clean)\n",
        "\n",
        "        # Gradient calculation\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Metrics\n",
        "        with torch.no_grad():\n",
        "            batch_mse = F.mse_loss(recon, clean, reduction='none').view(clean.size(0), -1).mean(dim=1)\n",
        "            batch_psnr = psnr_from_mse(batch_mse).mean().item()\n",
        "            train_loss_meter.update(loss.item() * max(1, cfg.accum_steps), n=clean.size(0))\n",
        "            train_psnr_meter.update(batch_psnr, n=clean.size(0))\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #     for step, (noisy, clean) in enumerate(val_loader, start=1):\n",
        "    #         noisy = noisy.to(device, non_blocking=True)\n",
        "    #         clean = clean.to(device, non_blocking=True)\n",
        "\n",
        "    #         recon = model(noisy)\n",
        "\n",
        "    #         batch_mse = F.mse_loss(recon, clean, reduction='none').view(clean.size(0), -1).mean(dim=1)\n",
        "    #         batch_psnr = psnr_from_mse(batch_mse).mean().item()\n",
        "    #         val_loss_meter.update(loss.item() * max(1, cfg.accum_steps), n=clean.size(0))\n",
        "    #         val_psnr_meter.update(batch_psnr, n=clean.size(0))\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"loss\": train_loss_meter.avg,\n",
        "        \"psnr\": train_psnr_meter.avg,\n",
        "        # \"val_loss\": val_loss_meter.avg,\n",
        "        # \"val_psnr\": val_psnr_meter.avg\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             test_loader: DataLoader,\n",
        "             device: str,\n",
        "             loss_fn: nn.Module) -> Dict[str, float]:\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter()\n",
        "    psnr_meter = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        for noisy, clean in test_loader:\n",
        "            noisy = noisy.to(device, non_blocking=True)\n",
        "            clean = clean.to(device, non_blocking=True)\n",
        "            recon = model(noisy)\n",
        "            loss = loss_fn(recon, clean)\n",
        "            batch_mse = F.mse_loss(recon, clean, reduction='none').view(clean.size(0), -1).mean(dim=1)\n",
        "            batch_psnr = psnr_from_mse(batch_mse).mean().item()\n",
        "            loss_meter.update(loss.item(), n=clean.size(0))\n",
        "            psnr_meter.update(batch_psnr, n=clean.size(0))\n",
        "    return {\"loss\": loss_meter.avg, \"psnr\": psnr_meter.avg}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOU1Wi2I8XxY"
      },
      "source": [
        "Checks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUIrw-Cw73Pa"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(\n",
        "    path: str,\n",
        "    model: nn.Module,\n",
        "    scheduler: Optional[_LRScheduler],\n",
        "    scaler: Optional[torch.cuda.amp.GradScaler],\n",
        "    epoch: int,\n",
        "    cfg: TrainConfig,\n",
        "    best_val: float\n",
        "):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\n",
        "        \"model\": model.state_dict(),\n",
        "        \"scheduler\": None if scheduler is None else scheduler.state_dict(),\n",
        "        \"scaler\": None if scaler is None else scaler.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"cfg\": asdict(cfg),\n",
        "        \"best_val\": best_val,\n",
        "    }, path)\n",
        "\n",
        "\n",
        "def load_checkpoint(\n",
        "    path: str,\n",
        "    model: nn.Module,\n",
        "    scheduler: Optional[_LRScheduler] = None,\n",
        "    scaler: Optional[torch.cuda.amp.GradScaler] = None,\n",
        "    map_location: Optional[str] = None\n",
        ") -> Tuple[int, float, TrainConfig]:\n",
        "    ckpt = torch.load(path, map_location=map_location)\n",
        "    model.load_state_dict(ckpt[\"model\"])\n",
        "    # if optimizer is not None and ckpt.get(\"optimizer\") is not None:\n",
        "    #     optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "    if scheduler is not None and ckpt.get(\"scheduler\") is not None:\n",
        "        scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "    if scaler is not None and ckpt.get(\"scaler\") is not None:\n",
        "        scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "    start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "    best_val = float(ckpt.get(\"best_val\", float(\"inf\")))\n",
        "    cfg_dict = ckpt.get(\"cfg\", {})\n",
        "    cfg = TrainConfig(**cfg_dict) if cfg_dict else TrainConfig()\n",
        "    return start_epoch, best_val, cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eJenHcW8Tso"
      },
      "source": [
        "Fit Loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRk0AbBW78Uy"
      },
      "outputs": [],
      "source": [
        "def fit(model: nn.Module,\n",
        "        train_loader: DataLoader,\n",
        "        val_loader: DataLoader,\n",
        "        cfg: TrainConfig) -> Dict[str, Any]:\n",
        "    seed_all(cfg.seed)\n",
        "    device = cfg.device\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = create_optimizer(model, cfg)\n",
        "    steps_per_epoch = max(1, math.ceil(len(train_loader.dataset) / (cfg.batch_size)))\n",
        "    scheduler = create_scheduler(optimizer, cfg, steps_per_epoch)\n",
        "    loss_fn = create_loss(cfg)\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp)\n",
        "\n",
        "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "    last_path = os.path.join(cfg.out_dir, cfg.ckpt_last)\n",
        "    best_path = os.path.join(cfg.out_dir, cfg.ckpt_best)\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    if cfg.resume and os.path.isfile(cfg.resume):\n",
        "        start_epoch, best_val_loss, _ = load_checkpoint(cfg.resume, model, scheduler, scaler, map_location=device)\n",
        "        print(f\"[Resume] Starting from epoch {start_epoch}, best_val_loss={best_val_loss:.6f}\")\n",
        "\n",
        "    log_dict = {}\n",
        "\n",
        "    for epoch in range(start_epoch, cfg.epochs + 1):\n",
        "        # Train\n",
        "        train_stats = train_one_epoch(model, train_loader, optimizer, device, loss_fn, scaler, cfg)\n",
        "        if scheduler is not None:\n",
        "            # Step per-iteration schedulers are already stepped inside; ours is per-iteration via SequentialLR/LinearLR\n",
        "            # For simplicity, step here once per epoch when using epoch-based T_max.\n",
        "            try:\n",
        "                scheduler.step()\n",
        "            except TypeError:\n",
        "                # Some schedulers require step() every iteration; we chose epoch-wise to keep it simple.\n",
        "                pass\n",
        "\n",
        "        # Validate\n",
        "        val_stats = evaluate(model, val_loader, device, loss_fn)\n",
        "\n",
        "        # Logging\n",
        "        print(f\"Epoch {epoch:03d}/{cfg.epochs} | \"\n",
        "              f\"Train loss {train_stats['loss']:.6f} PSNR {train_stats['psnr']:.2f} dB | \"\n",
        "              f\"Val loss {val_stats['loss']:.6f} PSNR {val_stats['psnr']:.2f} dB | \"\n",
        "              f\"LR {optimizer.param_groups[0]['lr']:.6g}\")\n",
        "        log_dict[epoch] = {**train_stats, **val_stats}\n",
        "\n",
        "        # Checkpoints\n",
        "        save_checkpoint(last_path, model, scheduler, scaler, epoch, cfg, best_val_loss)\n",
        "        if val_stats[\"loss\"] < best_val_loss:\n",
        "            best_val_loss = val_stats[\"loss\"]\n",
        "            save_checkpoint(best_path, model, scheduler, scaler, epoch, cfg, best_val_loss)\n",
        "            print(f\"[Best] Val loss improved to {best_val_loss:.6f} -> saved {best_path}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return {\"best_val_loss\": best_val_loss}, log_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXyAfwf6ji4N"
      },
      "source": [
        "Driver Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1pOXEroiuQA"
      },
      "outputs": [],
      "source": [
        "model = Autoencoder(Encoder(in_channels=3), Decoder(in_channels=3))\n",
        "cfg = TrainConfig(\n",
        "    epochs=5,\n",
        "    batch_size=4,\n",
        "    optimizer=\"Adam\",\n",
        "    device=\"cpu\",\n",
        "    out_dir=\"./outputs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q6rttFlhlFLH",
        "outputId": "bd2cb3ca-20f7-49b9-ab73-db0e2fee29dd"
      },
      "outputs": [],
      "source": [
        "best_loss, log_dict = fit(model, training_NIDS_loader, validate_NIDS_loader, cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjS_mgZG6DIc"
      },
      "source": [
        "Krishna - Metrics log and test code"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
