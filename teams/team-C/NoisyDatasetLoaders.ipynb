{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"tarunpathak/natural-images-with-synthetic-noise\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-GCUBmmtUJT",
        "outputId": "0ee587b8-6935-46f1-a0df-60f4dc8366c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'natural-images-with-synthetic-noise' dataset.\n",
            "Path to dataset files: /kaggle/input/natural-images-with-synthetic-noise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3zYXv5CMtG4O"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from typing import Optional, Tuple\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "#Creates a custom dataset by inheriting from PyTorch’s Dataset class.\n",
        "\n",
        "class PairedNISN(Dataset):\n",
        "    \"\"\"\n",
        "    Expects:\n",
        "      <split>/\n",
        "        noisy images/*.jpg\n",
        "        ground truth/*.jpg\n",
        "    Example split paths: /content/NISN/train/train, /content/NISN/validate/validate, /content/NISN/test/test\n",
        "    Pairs by removing the noise prefix before the first '_' in the noisy filename.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, split_root: str, resize_to: Optional[Tuple[int,int]] = None):\n",
        "\n",
        "      #Optional[Tuple[int,int]] = None:  Resize target or keep original\n",
        "        self.root = Path(split_root)\n",
        "        self.noisy_dir = self.root / \"noisy images\"   # → /content/NISN/train/train/noisy images\n",
        "        self.clean_dir = self.root / \"ground truth\"   # → /content/NISN/train/train/ground truth\n",
        "\n",
        "        #Path(split_root) converts the string (like \"/content/NISN/train/train\") into a Path object.\n",
        "        #.is_dir() → checks if the path points to a directory\n",
        "        #.is_file() → checks if the path points to a file\n",
        "        #.exists() → checks if the path exists at all\n",
        "        assert self.noisy_dir.is_dir() and self.clean_dir.is_dir(), \"NISN folders not found.\"\n",
        "\n",
        "        #In Java (similar idea) for condition checking:\n",
        "        #assert noisyDir.exists() && cleanDir.exists() : \"NISN folders not found.\";\n",
        "        # transforms: ToTensor() only -> values in [0,1]\n",
        "        t = []\n",
        "\n",
        "        #Checks if the user provided a resize target when creating the dataset.\n",
        "        if resize_to is not None:\n",
        "            t.append(transforms.Resize(resize_to))\n",
        "        t.append(transforms.ToTensor())\n",
        "\n",
        "        \"\"\"\n",
        "        transforms.ToTensor() does three things:\n",
        "        Converts the image from a PIL object (used by Pillow) to a PyTorch tensor.\n",
        "\n",
        "        Reorders the dimensions from (H, W, C) → (C, H, W) (channel-first).\n",
        "\n",
        "        Scales pixel values from [0, 255] → [0, 1] (float32).\n",
        "        \"\"\"\n",
        "        #So now our list might be: t = [transforms.Resize((32, 32)), transforms.ToTensor()]\n",
        "        #or just : t = [transforms.ToTensor()], if if no resize is used.\n",
        "        self.transform = transforms.Compose(t)\n",
        "\n",
        "        #This combines all the transformations in the list t into one pipeline using Compose.\n",
        "        #So self.transform becomes a callable object that you can apply to any image:\n",
        "        #Ex: img_tensor = self.transform(image)\n",
        "        #and it will automatically apply each transformation in order.\n",
        "        # build pairs by stripping the noise tag ('gauss_...')\n",
        "        #We only use this function on the noisy image filenames, not the clean ones.\n",
        "        # Ex: gauss_127215712_ff5b654d07_c.jpg -> 127215712_ff5b654d07_c.jpg\n",
        "\n",
        "        def base_clean_name(name: str) -> str:\n",
        "            # drop everything up to first underscore\n",
        "            i = name.find('_')\n",
        "            return name[i+1:] if i != -1 else name\n",
        "             # slice after '_' ; if no '_', return the original name\n",
        "        # support jpg/jpeg/png\n",
        "        exts = (\"*.jpg\", \"*.jpeg\", \"*.png\")\n",
        "        noisy_paths = []\n",
        "        for e in exts:\n",
        "            noisy_paths.extend(self.noisy_dir.glob(e))\n",
        "        noisy_paths = sorted(noisy_paths)\n",
        "\n",
        "        #noisy_paths becomes a list of full file paths to all noisy images, sorted alphabetically.\n",
        "        \"\"\"\n",
        "        [\n",
        "            Path('/content/NISN/train/train/noisy images/gauss_127215712_ff5b654d07_c.jpg'),\n",
        "            Path('/content/NISN/train/train/noisy images/gauss_128819241_bb4a3c5f71_c.jpg'),\n",
        "            ...\n",
        "            ]\n",
        "        \"\"\"\n",
        "\n",
        "        clean_index = {}\n",
        "        for e in exts:\n",
        "            for p in self.clean_dir.glob(e):\n",
        "                clean_index[p.name] = p\n",
        "\n",
        "                #p.name → just the filename, e.g. \"40321670583_403f81a527_c.jpg\".\n",
        "                #p → the full path, e.g. Path('/content/.../ground truth/40321670583_403f81a527_c.jpg').\n",
        "        \"\"\"\n",
        "        clean_index[\"40321670583_403f81a527_c.jpg\"] = Path('/content/.../ground truth/40321670583_403f81a527_c.jpg')\n",
        "\n",
        "        or:\n",
        "\n",
        "        { \"40321670583_403f81a527_c.jpg\": Path(.../ground truth/40321670583_403f81a527_c.jpg) }\n",
        "\n",
        "        \"\"\"\n",
        "        #self.pairs will be a list of tuples\n",
        "        \"\"\"\n",
        "\n",
        "        Ex: Path('/content/NISN/train/train/noisy images/gauss_127215712_ff5b654d07_c.jpg')\n",
        "\n",
        "        Each entry is a Path object (from pathlib), not a plain string:\n",
        "\n",
        "        noisePath = noisy_paths[0]\n",
        "        print(noisePath)         # full path\n",
        "        print(noisePath.name)    # filename only, e.g. 'gauss_127215712_ff5b654d07_c.jpg'\n",
        "        print(noisePath.stem)    # filename without extension, e.g. 'gauss_127215712_ff5b654d07_c'\n",
        "        print(noisePath.suffix)  # extension only, e.g. '.jpg'\n",
        "        \"\"\"\n",
        "\n",
        "        self.pairs = []\n",
        "        missing = []\n",
        "\n",
        "        for noisePath in noisy_paths:\n",
        "            cleanName = base_clean_name(noisePath.name) # Ex: gauss_127215712_ff5b654d07_c.jpg -> 127215712_ff5b654d07_c.jpg\n",
        "            cleanPath = clean_index.get(cleanName)     #   clean_index.get(127215712_ff5b654d07_c.jpg)\n",
        "                                               # use key (file name) to find value\n",
        "                                               #which returns path of clean image\n",
        "            if cleanPath is None:\n",
        "                missing.append((noisePath.name, cleanName))\n",
        "            else:\n",
        "                self.pairs.append((noisePath, cleanPath))\n",
        "\n",
        "                #self.pairs is a list of tuples where each tuple contains\n",
        "                # the file paths of a noisy–clean image pair with the same base name.\n",
        "\n",
        "        if missing:\n",
        "            print(f\"[warning] {len(missing)} noisy files had no matching clean image. first few:\")\n",
        "            for n, c in missing[:5]:\n",
        "                print(f\"  noisy: {n}  -> expected: {c}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisePath, cleanPath = self.pairs[idx]\n",
        "\n",
        "        noisy = Image.open(noisePath).convert(\"RGB\")\n",
        "        clean = Image.open(cleanPath).convert(\"RGB\")\n",
        "\n",
        "        #uses Pillow (PIL) to open the image file from disk.\n",
        "        #result is a PIL Image object, not yet a tensor\n",
        "        #.convert(\"RGB\"): This forces the image into RGB color mode.\n",
        "        #Each channel’s value ranges from 0 to 255 (as integers)\n",
        "        #Ex: [255, 255, 0]   # R=255, G=255, B=0 → yellow\n",
        "\n",
        "        return self.transform(noisy), self.transform(clean)\n",
        "              #turn [255, 255, 0] into a PyTorch tensor (0–1 range), rearranged into channel-first\n",
        "        \"\"\"\n",
        "              Ex:\n",
        "              noisy image is a small yellow pixel:\n",
        "              noisy_pixel_RGB = [255, 255, 0]   # R=255, G=255, B=0\n",
        "              clean image pixel is a darker yellow:\n",
        "              clean_pixel_RGB = [128, 128, 0]\n",
        "\n",
        "              After self.tfm(noisy):\n",
        "\n",
        "              1. Convert to float and scale to [0,1]:\n",
        "              [255, 255, 0] → [1.0, 1.0, 0.0]\n",
        "              [128, 128, 0] → [0.502, 0.502, 0.0]\n",
        "\n",
        "              2. Change shape:\n",
        "              Before: (H, W, C) → typical image shape like (512, 512, 3)\n",
        "              After: (C, H, W) → tensor shape (3, 512, 512)\n",
        "\n",
        "              3. Convert to tensor:\n",
        "              Now both are torch.Tensor objects of type float32.\n",
        "\n",
        "         \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resize_to = None          # <- keep native 512x512\n",
        "\n",
        "# The dataset_name variable is not needed for path construction as per the directory listing.\n",
        "train_ds = PairedNISN(f\"{path}/train/train\",    resize_to=resize_to)\n",
        "val_ds   = PairedNISN(f\"{path}/validate/validate\", resize_to=resize_to)\n",
        "test_ds  = PairedNISN(f\"{path}/test/test\",     resize_to=resize_to)"
      ],
      "metadata": {
        "id": "BE4D6MCjuCjM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "f3b54955",
        "outputId": "07167fe9-d7a3-4fdc-e062-eaf2eb084b15"
      },
      "source": [
        "'''\n",
        "--------------FOR DEBUGGING--------------\n",
        "# List contents of the 'train' split folder\n",
        "train_split_path = f\"{path}/train\"\n",
        "print(f\"Contents of {train_split_path}:\")\n",
        "for item in os.listdir(train_split_path):\n",
        "    print(f\"- {item}\")\n",
        "'''"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n--------------FOR DEBUGGING--------------\\n# List contents of the \\'train\\' split folder\\ntrain_split_path = f\"{path}/train\"\\nprint(f\"Contents of {train_split_path}:\")\\nfor item in os.listdir(train_split_path):\\n    print(f\"- {item}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "d03aeddc",
        "outputId": "ee86e5b0-e82d-4ec9-bbce-babc29a2cf2d"
      },
      "source": [
        "\"\"\"\n",
        "-----------FOR DEBUGGING-------------\n",
        "# List contents of the base path where the dataset is extracted\n",
        "print(f\"Contents of {path}:\")\n",
        "for item in os.listdir(path):\n",
        "    print(f\"- {item}\")\n",
        "\n",
        "# If there's a single main dataset folder (e.g., 'natural-images-with-synthetic-noise'), list its contents too\n",
        "# Assuming dataset_name is correctly set as 'natural-images-with-synthetic-noise'\n",
        "full_dataset_path = os.path.join(path, dataset_name)\n",
        "if os.path.isdir(full_dataset_path):\n",
        "    print(f\"\\nContents of {full_dataset_path}:\")\n",
        "    for item in os.listdir(full_dataset_path):\n",
        "        print(f\"- {item}\")\n",
        "\"\"\""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n-----------FOR DEBUGGING-------------\\n# List contents of the base path where the dataset is extracted\\nprint(f\"Contents of {path}:\")\\nfor item in os.listdir(path):\\n    print(f\"- {item}\")\\n\\n# If there\\'s a single main dataset folder (e.g., \\'natural-images-with-synthetic-noise\\'), list its contents too\\n# Assuming dataset_name is correctly set as \\'natural-images-with-synthetic-noise\\'\\nfull_dataset_path = os.path.join(path, dataset_name)\\nif os.path.isdir(full_dataset_path):\\n    print(f\"\\nContents of {full_dataset_path}:\")\\n    for item in os.listdir(full_dataset_path):\\n        print(f\"- {item}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# pin is boolean\n",
        "pin = device.type == \"cuda\"\n",
        "\n",
        "# adjust batch_size to your VRAM; 512x512 is large → start small\n",
        "batch_size = 8 if resize_to is None else 64\n",
        "\n",
        "# Use 2 or 4 workers to speed up data loading in the background\n",
        "num_workers = 2 if device.type == \"cuda\" else 0 # Use 0 if on CPU\n",
        "\n",
        "train_loader = DataLoader(train_ds,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          pin_memory=pin,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "val_loader   = DataLoader(val_ds,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=False,\n",
        "                          pin_memory=pin,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "test_loader  = DataLoader(test_ds,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=False,\n",
        "                          pin_memory=pin,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "print(\"DataLoaders are ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEvavZEzuE-F",
        "outputId": "7f4bd5df-62a4-4b8f-c4cd-f95ece92a56c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "DataLoaders are ready!\n"
          ]
        }
      ]
    }
  ]
}